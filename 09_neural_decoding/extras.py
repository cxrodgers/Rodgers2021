import pandas
import numpy as np
import my.decoders

def define_folds(strats, n_splits, shuffle, n_tune_splits):
    """Fold the data separately by session
    
    Do this separately by session to ensure that each fold * strat is 
    equally represented
    """
    session_folds_l = []
    session_folds_keys_l = []
    for session in strats.index.levels[0]:
        # Get strats for this session
        session_strats = strats.loc[session]
        
        # Generate folds for this session
        session_folds = my.decoders.stratified_split_data(
            session_strats, 
            n_splits=n_splits, shuffle=shuffle, n_tune_splits=n_tune_splits,
            )
        
        # Store
        session_folds_l.append(session_folds)
        session_folds_keys_l.append(session)

    # Concat over sessions
    folds = pandas.concat(
        session_folds_l, keys=session_folds_keys_l, names=['session'])
    
    return folds
    
def resample_from_data(
    big_tm, spikes_by_bin,
    group_by=('rewside', 'choice'),
    n_resamples=10,
    ):
    """Resample trials across sessions by stimulus type.
    
    For every stimulus type (currently rewside * choice):
        Choose randomly one trial of this type from every session
        Repeat `n_resamples` times
    
    Held-out trials should be removed from big_tm before calling this function.
    
    big_tm : DataFrame
        index : MultiIndex session * trial
        columns : includes session, rewside, and choice columns
    
    spikes : Series
        index : MultiIndex session * trial * bin * neuron
        values : spike count from that neuron in that bin
    

    Returns: resampled_trials, resampled_spikes
    
    resampled_trials : DataFrame
        columns : MultiIndex rewside * choice * resample
        index : session
        values : trial number
    
    resampled_spikes : DataFrame
        columns : MultiIndex rewside * choice * resample
        index : MultiIndex session * bin * neuron
        values : spike count
    """
    ## Group by stimulus type
    assert group_by is not None
    group_by = list(group_by)
        
    gobj = big_tm.groupby(group_by + ['session'])
    
    
    ## Resample across sessions
    # For each stimulus type: take one trial from each session, 
    # repeat n_resamples times
    draw_keys_l = []
    drawn_trials_l = []
    for group_keys, sub_tm in gobj:
        # Find available trials
        available_trials = sub_tm.droplevel('session').index.values
        
        # Resample
        idxs = np.random.randint(0, len(available_trials), n_resamples)
        drawn_trials = available_trials[idxs]
        
        # Store
        drawn_trials_l.append(drawn_trials)
        draw_keys_l.append(group_keys)


    ## Concat the drawn trials
    midx = pandas.MultiIndex.from_tuples(
        draw_keys_l, names=(group_by + ['session']))
    resampled_trials = pandas.DataFrame(
        np.array(drawn_trials_l), index=midx).sort_index()
    resampled_trials.columns.name = 'resample'

    
    ## Put resampling groups (rewside * choice * resample) on columns
    # Then one row per session
    resampled_trials = resampled_trials.unstack(group_by).reorder_levels(
        group_by + ['resample'], axis=1).sort_index(axis=1)
    

    ## Now draw spikes
    # Stack the trials, one resampled trial per row
    slicing_df = resampled_trials.T.stack().rename('trial').reset_index()
    
    # Unstack so we can index by session * trial
    # This adds nans because neuron numbers don't line up
    unstacked = spikes_by_bin.unstack(['session', 'trial'])
    
    # Index by session * trial
    sliced_spikes_df2 = unstacked.loc[:, 
        pandas.MultiIndex.from_frame(slicing_df[['session', 'trial']])]
    
    # Relabel with resampling groups
    sliced_spikes_df2.columns = (
        pandas.MultiIndex.from_frame(
        slicing_df[group_by + ['resample', 'session']]))

    # Stack, to remove nans from misaligned neuron numbers
    resampled_spikes2 = sliced_spikes_df2.stack('session').astype(np.int)
    
    # Sort as expected
    resampled_spikes = resampled_spikes2.reorder_levels(
        ['session', 'bin', 'neuron']).sort_index()


    return resampled_trials, resampled_spikes


def resample_from_data_with_splits(
    big_tm,
    spikes_by_bin,
    folds,
    setname2n_resamples_per_split,
    group_by=('rewside', 'choice'),
    ):
    """Folds the data and separately resamples each fold into multiple sets.
    
    big_tm, spikes_by_bin : see resample_from_data
    
    folds : DataFrame
        index : whatever, e.g. session * trial
        columns : split number
        values : name of the dataset, e.g. 'test', 'train', or 'tune'
        This can be generated by my.decoders.stratified_split_data
    
    setname2n_resamples_per_split : dict
        keys : values of `folds`
        values : integer
            The number of resamples per split to choose from this dataset
    """
    ## Iterate over splits
    resampled_trials_l = []
    resampled_spikes_l = []
    keys_l = []
    for split_name in folds.columns:
        # Get the the setnames for this fold
        fold_setnames = folds.loc[:, split_name]
        
        
        ## Iterate over each setname within this fold
        for set_name in fold_setnames.unique():
            # Get the number of resamples for this setname
            setname_n_resamples = setname2n_resamples_per_split[set_name]
            
            # Get the mask for this setname
            mask = fold_setnames == set_name
            
            # Slice the data accordingly
            masked_big_tm = big_tm.loc[mask].copy()
            masked_big_tm.index = masked_big_tm.index.remove_unused_levels()
            
            # Resample
            # Bottleneck
            resampled_trials, resampled_spikes = resample_from_data(
                big_tm=masked_big_tm,
                spikes_by_bin=spikes_by_bin,
                n_resamples=setname_n_resamples,
                group_by=group_by,
            )
            
            # Error check
            assert not resampled_trials.isnull().any().any()

            # Store
            resampled_trials_l.append(resampled_trials)
            resampled_spikes_l.append(resampled_spikes)
            keys_l.append((split_name, set_name))


    ## Concat
    big_resampled_trials = pandas.concat(
        resampled_trials_l, keys=keys_l, names=[folds.columns.name, 'set'], 
        axis=1).sort_index(axis=0).sort_index(axis=1)
    
    big_resampled_spikes = pandas.concat(
        resampled_spikes_l, keys=keys_l, names=[folds.columns.name, 'set'], 
        axis=1).sort_index(axis=0).sort_index(axis=1)

    
    ## Error check that the same trials were not included in test and train
    for split_name in big_resampled_trials.columns.levels[0]:
        for session in big_resampled_trials.index:
            # Get test and train trials
            # TODO: add the other groups in group_names
            test_trials = big_resampled_trials.loc[
                session, (split_name, 'test')]
            train_trials = big_resampled_trials.loc[
                session, (split_name, 'train')]
        
            # Check that they don't overlap
            assert len(set(test_trials.values) & set(train_trials.values)) == 0
    

    return big_resampled_trials, big_resampled_spikes